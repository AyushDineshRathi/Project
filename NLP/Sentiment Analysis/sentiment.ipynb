{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    html = re.compile(r'[<#*?>]') \n",
    "    return html.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.S+')\n",
    "    return url.sub(r' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Punctuations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# string.punctuation #-----> { '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~' }\n",
    "# exclude = string.punctuation\n",
    "# print(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_punc1(text):\n",
    "#     return text.translate(str.maketrans(' ',  ' ', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review'] = df['review'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct the Spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def spell_corrector(incorrect_text):\n",
    "    return TextBlob(incorrect_text).correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes too much time --> Alos there is very few spelling error in the dataset \n",
    "# df['review'] = df['review'].apply(spell_corrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emoji Detection Regex\n",
    "emoji_pattern = re.compile(\n",
    "    \"[\\U0001F600-\\U0001F64F]\"  # Emoticons\n",
    "    \"|[\\U0001F300-\\U0001F5FF]\"  # Symbols & pictographs\n",
    "    \"|[\\U0001F680-\\U0001F6FF]\"  # Transport & map symbols\n",
    "    \"|[\\U0001F1E0-\\U0001F1FF]\"  # Flags (iOS)\n",
    "    \"|[\\U00002700-\\U000027BF]\"  # Dingbats\n",
    "    \"|[\\U000024C2-\\U0001F251]\"  # Enclosed characters\n",
    "    \"|[\\U0001F900-\\U0001F9FF]\"  # Supplemental Symbols and Pictographs\n",
    "    \"|[\\U0001FA70-\\U0001FAFF]\"  # Symbols and Pictographs Extended-A\n",
    "    \"|[\\U0001F004]\"             # Mahjong tile\n",
    "    \"|[\\U0001F0CF]\"             # Playing card black joker\n",
    "    , flags=re.UNICODE)\n",
    "\n",
    "# Check if any emoji is present\n",
    "df['contains_emoji'] = df['review'].apply(lambda x: bool(emoji_pattern.search(x)))\n",
    "df[df['contains_emoji'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Emojis with their meanings\n",
    "import emoji\n",
    "def replace_emojis(text):\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "df['review'] = df.review.apply(replace_emojis)\n",
    "df.review[3827]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append('C:/Users/Ayush R/AppData/Roaming/nltk_data')\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import pickle\n",
    "\n",
    "# Path to punkt tokenizer\n",
    "path = 'C:/Users/Ayush R/AppData/Roaming/nltk_data/tokenizers/punkt/english.pickle'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Tokenize the text\n",
    "text = \"This is a sentence. This is another one.\"\n",
    "sentences = tokenizer.tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review_sentences'] = df['review_new'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['review_sentences'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['contains_emoji'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import pickle\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# Path to the word tokenizer (usually Treebank tokenizer is used for word tokenization)\n",
    "path = 'C:/Users/Ayush R/AppData/Roaming/nltk_data/tokenizers/punkt/english.pickle'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Initialize Treebank Word Tokenizer (uses the punkt tokenizer for word tokenization)\n",
    "word_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# Tokenize the text\n",
    "text = \"This is a sentence. Here's another one!\"\n",
    "words = word_tokenizer.tokenize(text)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lambda x: word_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    if isinstance(text, str):  \n",
    "        return \" \".join([ps.stem(word) for word in text.split()])\n",
    "    return text  \n",
    "\n",
    "df['review'] = df['review'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "max_len = 1000\n",
    "\n",
    "token = Tokenizer(num_words=max_words)\n",
    "token.fit_on_texts(df['review'])\n",
    "sequences = token.texts_to_sequences(df['review'])\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = df.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dropout(0.3),  # here we reduce overfitting\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=4,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    text = text.lower()\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_url(text)\n",
    "    text = replace_emojis(text)\n",
    "    text = spell_corrector(text)\n",
    "    text = word_tokenizer.tokenize(text)\n",
    "    text = stem_words(text)\n",
    "    sequence = token.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return \"positive\" if prediction > 0.5 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = \"The movie was fantastic! I really enjoyed it.\"\n",
    "print(f\"Review: {new_review}\")\n",
    "print(f\"Sentiment: {predict_sentiment(new_review)}\")\n",
    "new_review = \"I did not enjoy the movie because of the noise inside cinema as well as the worst scene ever.\"\n",
    "print(f\"Review: {new_review}\")\n",
    "print(f\"Sentiment: {predict_sentiment(new_review)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = \"The movie was pathetic\"\n",
    "print(f\"Review: {new_review}\")\n",
    "print(f\"Sentiment: {predict_sentiment(new_review)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_url(text)\n",
    "    text = replace_emojis(text)\n",
    "    text = spell_corrector(text)\n",
    "    text = word_tokenizer.tokenize(text)\n",
    "    text = stem_words(text)\n",
    "    sequence = token.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_file', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_file', 'rb') as f:\n",
    "    mp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = \"The film was nice...\"\n",
    "reviews = preprocess(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.round(mp.predict(new_review))\n",
    "print(\"Positive\" if pred == 1 else \"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
