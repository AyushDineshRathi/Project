{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush R\\AppData\\Local\\Temp\\ipykernel_17608\\2292856915.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Gender'].replace({'Female': 0, 'Male': 1}, inplace=True)\n",
      "C:\\Users\\Ayush R\\AppData\\Local\\Temp\\ipykernel_17608\\2292856915.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Gender'].replace({'Female': 0, 'Male': 1}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Gender'].replace({'Female': 0, 'Male': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(data=df, columns=['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush R\\AppData\\Local\\Temp\\ipykernel_17608\\44622015.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df1[i].replace({True: 1, False: 0}, inplace=True)\n",
      "C:\\Users\\Ayush R\\AppData\\Local\\Temp\\ipykernel_17608\\44622015.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1[i].replace({True: 1, False: 0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "col = ['Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
    "for i in col:\n",
    "    df1[i].replace({True: 1, False: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                  0                0  \n",
       "1                  0                1  \n",
       "2                  0                0  \n",
       "3                  0                0  \n",
       "4                  0                1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore            int64\n",
       "Gender                 int64\n",
       "Age                    int64\n",
       "Tenure                 int64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Exited                 int64\n",
       "Geography_France       int64\n",
       "Geography_Germany      int64\n",
       "Geography_Spain        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_col = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Tenure', 'NumOfProducts']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df1[scale_col] = scaler.fit_transform(df1[scale_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0        0.538       0  0.324324     0.2  0.000000       0.000000          1   \n",
       "1        0.516       0  0.310811     0.1  0.334031       0.000000          0   \n",
       "2        0.304       0  0.324324     0.8  0.636357       0.666667          1   \n",
       "3        0.698       0  0.283784     0.1  0.000000       0.333333          0   \n",
       "4        1.000       0  0.337838     0.2  0.500246       0.000000          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1         0.506735       1                 1   \n",
       "1               1         0.562709       0                 0   \n",
       "2               0         0.569654       1                 1   \n",
       "3               0         0.469120       0                 1   \n",
       "4               1         0.395400       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                  0                0  \n",
       "1                  0                1  \n",
       "2                  0                0  \n",
       "3                  0                0  \n",
       "4                  0                1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited',axis='columns')\n",
    "y = df1['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>0.752</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>0.476</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948551</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9238</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646869</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>0.402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.517012</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>0.602</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421898</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7542</th>\n",
       "      <td>0.314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.303413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7524</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925815</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9412</th>\n",
       "      <td>0.750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.393324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668609</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>0.684</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567526</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "7751        0.800       0  0.283784     0.6  0.000000       0.333333   \n",
       "4154        0.752       1  0.216216     0.3  0.000000       0.333333   \n",
       "3881        0.476       0  0.621622     0.3  0.000000       0.000000   \n",
       "9238        0.846       0  0.432432     0.4  0.000000       0.333333   \n",
       "5210        0.402       1  0.229730     0.7  0.517012       0.333333   \n",
       "7487        0.602       0  0.513514     0.4  0.000000       0.000000   \n",
       "7542        0.314       0  0.216216     0.4  0.000000       0.333333   \n",
       "7524        0.620       0  0.297297     0.8  0.666330       0.000000   \n",
       "9412        0.750       1  0.108108     0.6  0.393324       0.000000   \n",
       "6377        0.684       1  0.202703     0.9  0.000000       0.000000   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "7751          0               0         0.096273                 0   \n",
       "4154          1               0         0.981478                 1   \n",
       "3881          1               1         0.948551                 1   \n",
       "9238          1               0         0.646869                 1   \n",
       "5210          0               0         0.434670                 1   \n",
       "7487          0               0         0.421898                 1   \n",
       "7542          1               1         0.303413                 0   \n",
       "7524          1               1         0.925815                 1   \n",
       "9412          0               0         0.668609                 1   \n",
       "6377          1               0         0.567526                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "7751                  0                1  \n",
       "4154                  0                0  \n",
       "3881                  0                0  \n",
       "9238                  0                0  \n",
       "5210                  0                0  \n",
       "7487                  0                0  \n",
       "7542                  0                1  \n",
       "7524                  0                0  \n",
       "9412                  0                0  \n",
       "6377                  0                0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush R\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.7912 - loss: 0.5408\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.7877 - loss: 0.4954\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.8031 - loss: 0.4558\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.7995 - loss: 0.4555\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.8035 - loss: 0.4559\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.8152 - loss: 0.4318\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.8112 - loss: 0.4288\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.8207 - loss: 0.4180\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.8170 - loss: 0.4253\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8299 - loss: 0.3934\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.8302 - loss: 0.3931\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.8298 - loss: 0.3936\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8368 - loss: 0.3808\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.8403 - loss: 0.3790\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.8375 - loss: 0.3784\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8396 - loss: 0.3720\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.8479 - loss: 0.3634\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.8559 - loss: 0.3540\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.8494 - loss: 0.3615\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.8517 - loss: 0.3547\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.8482 - loss: 0.3650\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.8530 - loss: 0.3591\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.8559 - loss: 0.3480\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.8539 - loss: 0.3588\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8618 - loss: 0.3359\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8573 - loss: 0.3491\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.8674 - loss: 0.3320\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.8598 - loss: 0.3458\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8583 - loss: 0.3430\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.8646 - loss: 0.3381\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8628 - loss: 0.3380\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.8550 - loss: 0.3481\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.8628 - loss: 0.3382\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.8636 - loss: 0.3390\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.8574 - loss: 0.3473\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8620 - loss: 0.3346\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.8673 - loss: 0.3253\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.8526 - loss: 0.3433\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.8674 - loss: 0.3320\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.8628 - loss: 0.3304\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.8601 - loss: 0.3358\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.8594 - loss: 0.3343\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.8581 - loss: 0.3365\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.8690 - loss: 0.3204\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8617 - loss: 0.3340\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.8665 - loss: 0.3264\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.8662 - loss: 0.3246\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8595 - loss: 0.3327\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.8716 - loss: 0.3108\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.8674 - loss: 0.3254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c6d0836390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(12, input_shape = (12,), activation = 'relu'),\n",
    "    keras.layers.Dense(6, activation = 'relu'),\n",
    "    keras.layers.Dense(3, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.8536 - loss: 0.3535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3514925241470337, 0.8535000085830688]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step\n"
     ]
    }
   ],
   "source": [
    "yp = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in yp:\n",
    "    if i >= 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7054    0\n",
       "442     0\n",
       "3954    0\n",
       "2288    0\n",
       "3196    0\n",
       "6178    0\n",
       "8351    0\n",
       "5658    1\n",
       "2065    0\n",
       "413     1\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      1760\n",
      "           1       0.43      0.73      0.55       240\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.70      0.80      0.73      2000\n",
      "weighted avg       0.90      0.85      0.87      2000\n",
      "\n",
      "[[1531  229]\n",
      " [  64  176]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model1 = keras.Sequential([\n",
    "        keras.layers.Dense(12, input_shape = (12,), activation='relu'),\n",
    "        keras.layers.Dense(4, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model1.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model1.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model1.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
    "    \n",
    "    print(model1.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model1.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush R\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.7867 - loss: 0.5517\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.7990 - loss: 0.4778\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.8082 - loss: 0.4603\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.8119 - loss: 0.4516\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.8122 - loss: 0.4440\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.8119 - loss: 0.4385\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.8152 - loss: 0.4323\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.8184 - loss: 0.4303\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.8204 - loss: 0.4242\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.8228 - loss: 0.4202\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.8245 - loss: 0.4178\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8226 - loss: 0.4133\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.8188 - loss: 0.4119\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.8256 - loss: 0.4038\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.8278 - loss: 0.4001\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.8232 - loss: 0.4014\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.8286 - loss: 0.3927\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.8307 - loss: 0.3916\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.8405 - loss: 0.3702\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.8410 - loss: 0.3716\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.8520 - loss: 0.3640\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.8434 - loss: 0.3678\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.8440 - loss: 0.3606\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8448 - loss: 0.3602\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8461 - loss: 0.3614\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.8491 - loss: 0.3568\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.8481 - loss: 0.3548\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.8497 - loss: 0.3557\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8435 - loss: 0.3569\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.8456 - loss: 0.3561\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.8489 - loss: 0.3608\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.8497 - loss: 0.3486\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.8519 - loss: 0.3523\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.8439 - loss: 0.3608\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.8573 - loss: 0.3456\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8591 - loss: 0.3421\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8474 - loss: 0.3517\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.8497 - loss: 0.3532\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.8546 - loss: 0.3483\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8473 - loss: 0.3600\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.8503 - loss: 0.3534\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.8598 - loss: 0.3364\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.8493 - loss: 0.3476\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.8550 - loss: 0.3388\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.8537 - loss: 0.3482\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.8580 - loss: 0.3397\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8561 - loss: 0.3426\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8574 - loss: 0.3412\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8594 - loss: 0.3343\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.8547 - loss: 0.3425\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.8603 - loss: 0.3351\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.8575 - loss: 0.3439\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.8539 - loss: 0.3441\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.8609 - loss: 0.3385\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.8592 - loss: 0.3355\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.8527 - loss: 0.3392\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.8588 - loss: 0.3448\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.8590 - loss: 0.3350\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.8525 - loss: 0.3402\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.8634 - loss: 0.3287\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.8642 - loss: 0.3279\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.8600 - loss: 0.3367\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.8635 - loss: 0.3301\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8585 - loss: 0.3406\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.8616 - loss: 0.3301\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8574 - loss: 0.3394\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.8556 - loss: 0.3394\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8609 - loss: 0.3306\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.8639 - loss: 0.3235\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.8566 - loss: 0.3380\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8613 - loss: 0.3353\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.8582 - loss: 0.3381\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.8651 - loss: 0.3297\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.8575 - loss: 0.3417\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.8565 - loss: 0.3431\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.8575 - loss: 0.3391\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.8623 - loss: 0.3339\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.8651 - loss: 0.3335\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.8666 - loss: 0.3234\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.8606 - loss: 0.3335\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.8651 - loss: 0.3272\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.8618 - loss: 0.3316\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.8655 - loss: 0.3319\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.8631 - loss: 0.3309\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.8667 - loss: 0.3268\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.8635 - loss: 0.3363\n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.8666 - loss: 0.3270\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.8551 - loss: 0.3434\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.8574 - loss: 0.3431\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.8624 - loss: 0.3258\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.8625 - loss: 0.3333\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.8623 - loss: 0.3366\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8672 - loss: 0.3335\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8703 - loss: 0.3243\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.8615 - loss: 0.3345\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.8647 - loss: 0.3284\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.8617 - loss: 0.3309\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.8649 - loss: 0.3261\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8632 - loss: 0.3330\n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.8616 - loss: 0.3380\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.8432 - loss: 0.3541\n",
      "[0.3508182764053345, 0.8475000262260437]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      1595\n",
      "           1       0.71      0.42      0.53       405\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.79      0.69      0.72      2000\n",
      "weighted avg       0.83      0.85      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n",
    "y_preds = np.round(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.91      1760\n",
      "         1.0       0.42      0.71      0.53       240\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.69      0.79      0.72      2000\n",
      "weighted avg       0.89      0.85      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since, Dataset is imbalanced, we would use some techniques to try making it balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here 0 has a lot of data over 1 and that's why ouor F1-score for 1 is much less than that of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    2037\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0, count_1 = df1.Exited.value_counts()\n",
    "\n",
    "df_class_0 = df1[df1.Exited == 0]\n",
    "df_class_1 = df1[df1.Exited == 1]\n",
    "\n",
    "df_class_0_undersample = df_class_0.sample(count_1)\n",
    "df_under = pd.concat([df_class_0_undersample, df_class_1], axis = 0)\n",
    "df_under.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_under.drop('Exited', axis = 1)\n",
    "y = df_under.Exited\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    1630\n",
       "0    1629\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush R\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.5034 - loss: 0.6894\n",
      "Epoch 2/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.5979 - loss: 0.6776\n",
      "Epoch 3/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.6452 - loss: 0.6547\n",
      "Epoch 4/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.6617 - loss: 0.6235\n",
      "Epoch 5/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.6630 - loss: 0.6191\n",
      "Epoch 6/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.6795 - loss: 0.6013\n",
      "Epoch 7/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.6664 - loss: 0.6110\n",
      "Epoch 8/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.6802 - loss: 0.6006\n",
      "Epoch 9/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.6840 - loss: 0.5933\n",
      "Epoch 10/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.6797 - loss: 0.5949\n",
      "Epoch 11/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.7005 - loss: 0.5817\n",
      "Epoch 12/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.6811 - loss: 0.5919\n",
      "Epoch 13/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.6915 - loss: 0.5815\n",
      "Epoch 14/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.7044 - loss: 0.5743\n",
      "Epoch 15/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7059 - loss: 0.5719\n",
      "Epoch 16/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.7042 - loss: 0.5746\n",
      "Epoch 17/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.7065 - loss: 0.5650\n",
      "Epoch 18/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7045 - loss: 0.5606\n",
      "Epoch 19/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7154 - loss: 0.5525\n",
      "Epoch 20/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.7210 - loss: 0.5528\n",
      "Epoch 21/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.7232 - loss: 0.5540\n",
      "Epoch 22/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7284 - loss: 0.5425\n",
      "Epoch 23/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7303 - loss: 0.5365\n",
      "Epoch 24/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7251 - loss: 0.5368\n",
      "Epoch 25/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.7461 - loss: 0.5152\n",
      "Epoch 26/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.7439 - loss: 0.5252\n",
      "Epoch 27/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.7400 - loss: 0.5192\n",
      "Epoch 28/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7480 - loss: 0.5134\n",
      "Epoch 29/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7398 - loss: 0.5157\n",
      "Epoch 30/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7492 - loss: 0.5031\n",
      "Epoch 31/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7553 - loss: 0.4958\n",
      "Epoch 32/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.7519 - loss: 0.5013\n",
      "Epoch 33/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.7575 - loss: 0.4938\n",
      "Epoch 34/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7594 - loss: 0.4833\n",
      "Epoch 35/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7482 - loss: 0.4957\n",
      "Epoch 36/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.7573 - loss: 0.4884\n",
      "Epoch 37/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7530 - loss: 0.4997\n",
      "Epoch 38/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7725 - loss: 0.4731\n",
      "Epoch 39/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7672 - loss: 0.4843\n",
      "Epoch 40/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7548 - loss: 0.4872\n",
      "Epoch 41/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.7590 - loss: 0.4844\n",
      "Epoch 42/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7537 - loss: 0.4901\n",
      "Epoch 43/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7624 - loss: 0.4847\n",
      "Epoch 44/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.7517 - loss: 0.4898\n",
      "Epoch 45/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.7677 - loss: 0.4728\n",
      "Epoch 46/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.7777 - loss: 0.4604\n",
      "Epoch 47/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7546 - loss: 0.4795\n",
      "Epoch 48/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.7621 - loss: 0.4766\n",
      "Epoch 49/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.7693 - loss: 0.4655\n",
      "Epoch 50/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.7669 - loss: 0.4742\n",
      "Epoch 51/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.7663 - loss: 0.4707\n",
      "Epoch 52/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.7755 - loss: 0.4593\n",
      "Epoch 53/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7625 - loss: 0.4696\n",
      "Epoch 54/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.7661 - loss: 0.4673\n",
      "Epoch 55/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7552 - loss: 0.4786\n",
      "Epoch 56/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7523 - loss: 0.4837\n",
      "Epoch 57/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7635 - loss: 0.4751\n",
      "Epoch 58/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.7803 - loss: 0.4509\n",
      "Epoch 59/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.7654 - loss: 0.4695\n",
      "Epoch 60/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7574 - loss: 0.4801\n",
      "Epoch 61/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7517 - loss: 0.4735\n",
      "Epoch 62/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7531 - loss: 0.4687\n",
      "Epoch 63/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7724 - loss: 0.4630\n",
      "Epoch 64/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7653 - loss: 0.4677\n",
      "Epoch 65/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7642 - loss: 0.4659\n",
      "Epoch 66/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7587 - loss: 0.4691\n",
      "Epoch 67/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7598 - loss: 0.4772\n",
      "Epoch 68/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.7545 - loss: 0.4836\n",
      "Epoch 69/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7610 - loss: 0.4787\n",
      "Epoch 70/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.7627 - loss: 0.4818\n",
      "Epoch 71/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.7572 - loss: 0.4788\n",
      "Epoch 72/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.7688 - loss: 0.4579\n",
      "Epoch 73/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7555 - loss: 0.4759\n",
      "Epoch 74/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.7593 - loss: 0.4825\n",
      "Epoch 75/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7787 - loss: 0.4485\n",
      "Epoch 76/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7662 - loss: 0.4526\n",
      "Epoch 77/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7783 - loss: 0.4560\n",
      "Epoch 78/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.7689 - loss: 0.4701\n",
      "Epoch 79/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.7723 - loss: 0.4509\n",
      "Epoch 80/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7680 - loss: 0.4692\n",
      "Epoch 81/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.7597 - loss: 0.4750\n",
      "Epoch 82/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.7527 - loss: 0.4769\n",
      "Epoch 83/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.7592 - loss: 0.4710\n",
      "Epoch 84/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.7557 - loss: 0.4766\n",
      "Epoch 85/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.7746 - loss: 0.4640\n",
      "Epoch 86/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7540 - loss: 0.4872\n",
      "Epoch 87/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7726 - loss: 0.4557\n",
      "Epoch 88/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7676 - loss: 0.4630\n",
      "Epoch 89/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.7757 - loss: 0.4583\n",
      "Epoch 90/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7677 - loss: 0.4764\n",
      "Epoch 91/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7564 - loss: 0.4825\n",
      "Epoch 92/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7716 - loss: 0.4671\n",
      "Epoch 93/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7773 - loss: 0.4578\n",
      "Epoch 94/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7729 - loss: 0.4595\n",
      "Epoch 95/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.7687 - loss: 0.4628\n",
      "Epoch 96/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7673 - loss: 0.4652\n",
      "Epoch 97/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.7624 - loss: 0.4760\n",
      "Epoch 98/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7657 - loss: 0.4692\n",
      "Epoch 99/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.7715 - loss: 0.4576\n",
      "Epoch 100/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.7696 - loss: 0.4695\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7573 - loss: 0.4721\n",
      "[0.4796122610569, 0.7558282017707825]\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75       408\n",
      "           1       0.74      0.79      0.76       407\n",
      "\n",
      "    accuracy                           0.76       815\n",
      "   macro avg       0.76      0.76      0.76       815\n",
      "weighted avg       0.76      0.76      0.76       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_under = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n",
    "y_pred_under = np.round(y_pred_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.77      0.75       381\n",
      "         1.0       0.79      0.74      0.76       434\n",
      "\n",
      "    accuracy                           0.76       815\n",
      "   macro avg       0.76      0.76      0.76       815\n",
      "weighted avg       0.76      0.76      0.76       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_under, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    7963\n",
       "0    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1_oversample = df_class_1.sample(count_0, replace=True)\n",
    "\n",
    "df_oversample = pd.concat([df_class_1_oversample, df_class_0], axis = 0)\n",
    "df_oversample.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversample = df_oversample.drop('Exited', axis = 1)\n",
    "y_oversample = df_oversample.Exited\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_oversample, y_oversample, test_size=0.2, random_state=42, stratify=y_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    6370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush R\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.5203 - loss: 0.6922\n",
      "Epoch 2/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.6543 - loss: 0.6328\n",
      "Epoch 3/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.6845 - loss: 0.5954\n",
      "Epoch 4/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.6966 - loss: 0.5830\n",
      "Epoch 5/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.7040 - loss: 0.5751\n",
      "Epoch 6/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7165 - loss: 0.5677\n",
      "Epoch 7/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7275 - loss: 0.5518\n",
      "Epoch 8/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7282 - loss: 0.5453\n",
      "Epoch 9/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7357 - loss: 0.5303\n",
      "Epoch 10/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.7480 - loss: 0.5189\n",
      "Epoch 11/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7545 - loss: 0.5115\n",
      "Epoch 12/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7480 - loss: 0.5144  \n",
      "Epoch 13/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7553 - loss: 0.5063\n",
      "Epoch 14/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7624 - loss: 0.4967\n",
      "Epoch 15/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.7609 - loss: 0.4942\n",
      "Epoch 16/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.7558 - loss: 0.4987\n",
      "Epoch 17/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.7696 - loss: 0.4837\n",
      "Epoch 18/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7704 - loss: 0.4790\n",
      "Epoch 19/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.7593 - loss: 0.4906\n",
      "Epoch 20/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7662 - loss: 0.4815\n",
      "Epoch 21/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.7661 - loss: 0.4852\n",
      "Epoch 22/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.7758 - loss: 0.4810\n",
      "Epoch 23/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.7644 - loss: 0.4792\n",
      "Epoch 24/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7684 - loss: 0.4787\n",
      "Epoch 25/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7672 - loss: 0.4786\n",
      "Epoch 26/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7706 - loss: 0.4789\n",
      "Epoch 27/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.7801 - loss: 0.4654\n",
      "Epoch 28/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.7718 - loss: 0.4679\n",
      "Epoch 29/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7763 - loss: 0.4664\n",
      "Epoch 30/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.7694 - loss: 0.4749\n",
      "Epoch 31/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7680 - loss: 0.4734\n",
      "Epoch 32/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7755 - loss: 0.4711\n",
      "Epoch 33/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.7699 - loss: 0.4708\n",
      "Epoch 34/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.7776 - loss: 0.4679\n",
      "Epoch 35/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7728 - loss: 0.4705\n",
      "Epoch 36/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.7785 - loss: 0.4632\n",
      "Epoch 37/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.7739 - loss: 0.4659\n",
      "Epoch 38/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7681 - loss: 0.4723\n",
      "Epoch 39/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.7686 - loss: 0.4682\n",
      "Epoch 40/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.7786 - loss: 0.4602\n",
      "Epoch 41/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.7751 - loss: 0.4663\n",
      "Epoch 42/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.7784 - loss: 0.4588\n",
      "Epoch 43/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7706 - loss: 0.4615\n",
      "Epoch 44/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7754 - loss: 0.4607\n",
      "Epoch 45/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7742 - loss: 0.4615\n",
      "Epoch 46/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7761 - loss: 0.4569\n",
      "Epoch 47/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.7705 - loss: 0.4682\n",
      "Epoch 48/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7800 - loss: 0.4619\n",
      "Epoch 49/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7778 - loss: 0.4584\n",
      "Epoch 50/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.7757 - loss: 0.4630\n",
      "Epoch 51/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7758 - loss: 0.4622\n",
      "Epoch 52/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.7753 - loss: 0.4636\n",
      "Epoch 53/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7740 - loss: 0.4619\n",
      "Epoch 54/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.7735 - loss: 0.4571\n",
      "Epoch 55/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7774 - loss: 0.4552\n",
      "Epoch 56/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7818 - loss: 0.4581\n",
      "Epoch 57/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7777 - loss: 0.4637\n",
      "Epoch 58/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7747 - loss: 0.4622\n",
      "Epoch 59/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7714 - loss: 0.4624\n",
      "Epoch 60/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7747 - loss: 0.4573\n",
      "Epoch 61/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7840 - loss: 0.4462\n",
      "Epoch 62/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.7806 - loss: 0.4544\n",
      "Epoch 63/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7733 - loss: 0.4633\n",
      "Epoch 64/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.7817 - loss: 0.4520\n",
      "Epoch 65/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.7778 - loss: 0.4545\n",
      "Epoch 66/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.7776 - loss: 0.4539\n",
      "Epoch 67/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7761 - loss: 0.4531\n",
      "Epoch 68/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7776 - loss: 0.4604\n",
      "Epoch 69/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.7844 - loss: 0.4535\n",
      "Epoch 70/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7775 - loss: 0.4546\n",
      "Epoch 71/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7821 - loss: 0.4561\n",
      "Epoch 72/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7785 - loss: 0.4518\n",
      "Epoch 73/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.7717 - loss: 0.4627\n",
      "Epoch 74/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7778 - loss: 0.4551\n",
      "Epoch 75/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.7768 - loss: 0.4552\n",
      "Epoch 76/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7759 - loss: 0.4602\n",
      "Epoch 77/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7795 - loss: 0.4548\n",
      "Epoch 78/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.7809 - loss: 0.4512\n",
      "Epoch 79/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.7771 - loss: 0.4570\n",
      "Epoch 80/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7757 - loss: 0.4593\n",
      "Epoch 81/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7846 - loss: 0.4484\n",
      "Epoch 82/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7824 - loss: 0.4502\n",
      "Epoch 83/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.7780 - loss: 0.4578\n",
      "Epoch 84/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7789 - loss: 0.4548\n",
      "Epoch 85/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7859 - loss: 0.4438\n",
      "Epoch 86/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7881 - loss: 0.4453\n",
      "Epoch 87/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7767 - loss: 0.4531\n",
      "Epoch 88/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.7847 - loss: 0.4443\n",
      "Epoch 89/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7792 - loss: 0.4453\n",
      "Epoch 90/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7831 - loss: 0.4461\n",
      "Epoch 91/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7867 - loss: 0.4477\n",
      "Epoch 92/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7862 - loss: 0.4486\n",
      "Epoch 93/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.7817 - loss: 0.4503\n",
      "Epoch 94/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.7825 - loss: 0.4558\n",
      "Epoch 95/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.7853 - loss: 0.4486\n",
      "Epoch 96/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.7792 - loss: 0.4569\n",
      "Epoch 97/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.7759 - loss: 0.4609\n",
      "Epoch 98/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7804 - loss: 0.4517\n",
      "Epoch 99/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.7808 - loss: 0.4497\n",
      "Epoch 100/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.7775 - loss: 0.4557\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7631 - loss: 0.4716\n",
      "[0.45204728841781616, 0.7806026339530945]\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1593\n",
      "           1       0.78      0.78      0.78      1593\n",
      "\n",
      "    accuracy                           0.78      3186\n",
      "   macro avg       0.78      0.78      0.78      3186\n",
      "weighted avg       0.78      0.78      0.78      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_oversample = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n",
    "y_pred_oversample = np.round(y_pred_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.78      0.78      1582\n",
      "         1.0       0.78      0.78      0.78      1604\n",
      "\n",
      "    accuracy                           0.78      3186\n",
      "   macro avg       0.78      0.78      0.78      3186\n",
      "weighted avg       0.78      0.78      0.78      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_oversample, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis = 1)\n",
    "y = df1.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    6370\n",
       "0    6370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_train, y_train)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush R\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.5455 - loss: 0.6907\n",
      "Epoch 2/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.6547 - loss: 0.6280\n",
      "Epoch 3/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.6860 - loss: 0.5944\n",
      "Epoch 4/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7070 - loss: 0.5665\n",
      "Epoch 5/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.7214 - loss: 0.5534\n",
      "Epoch 6/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7194 - loss: 0.5493\n",
      "Epoch 7/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7290 - loss: 0.5378\n",
      "Epoch 8/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7454 - loss: 0.5216\n",
      "Epoch 9/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.7516 - loss: 0.5056\n",
      "Epoch 10/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.7499 - loss: 0.5097\n",
      "Epoch 11/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.7570 - loss: 0.4950\n",
      "Epoch 12/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7736 - loss: 0.4759\n",
      "Epoch 13/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.7681 - loss: 0.4778\n",
      "Epoch 14/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.7684 - loss: 0.4746\n",
      "Epoch 15/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7752 - loss: 0.4668\n",
      "Epoch 16/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.7738 - loss: 0.4721\n",
      "Epoch 17/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.7727 - loss: 0.4688\n",
      "Epoch 18/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.7774 - loss: 0.4662\n",
      "Epoch 19/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7779 - loss: 0.4618\n",
      "Epoch 20/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.7723 - loss: 0.4649\n",
      "Epoch 21/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7773 - loss: 0.4585\n",
      "Epoch 22/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.7817 - loss: 0.4630\n",
      "Epoch 23/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7736 - loss: 0.4673\n",
      "Epoch 24/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7831 - loss: 0.4562\n",
      "Epoch 25/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.7744 - loss: 0.4630\n",
      "Epoch 26/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7814 - loss: 0.4553\n",
      "Epoch 27/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.7766 - loss: 0.4578\n",
      "Epoch 28/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7876 - loss: 0.4523\n",
      "Epoch 29/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7795 - loss: 0.4572\n",
      "Epoch 30/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.7783 - loss: 0.4617\n",
      "Epoch 31/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.7871 - loss: 0.4502\n",
      "Epoch 32/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7841 - loss: 0.4517\n",
      "Epoch 33/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7829 - loss: 0.4588\n",
      "Epoch 34/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.7822 - loss: 0.4517\n",
      "Epoch 35/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7795 - loss: 0.4549\n",
      "Epoch 36/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.7808 - loss: 0.4570\n",
      "Epoch 37/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7879 - loss: 0.4498\n",
      "Epoch 38/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.7838 - loss: 0.4543\n",
      "Epoch 39/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7830 - loss: 0.4514\n",
      "Epoch 40/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7917 - loss: 0.4445\n",
      "Epoch 41/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.7924 - loss: 0.4442\n",
      "Epoch 42/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.7885 - loss: 0.4478\n",
      "Epoch 43/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.7856 - loss: 0.4537\n",
      "Epoch 44/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.7870 - loss: 0.4524\n",
      "Epoch 45/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.7864 - loss: 0.4508\n",
      "Epoch 46/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.7921 - loss: 0.4445\n",
      "Epoch 47/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.7886 - loss: 0.4448\n",
      "Epoch 48/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.7875 - loss: 0.4456\n",
      "Epoch 49/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.7854 - loss: 0.4485\n",
      "Epoch 50/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.7969 - loss: 0.4413\n",
      "Epoch 51/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7884 - loss: 0.4436\n",
      "Epoch 52/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.7907 - loss: 0.4462\n",
      "Epoch 53/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7850 - loss: 0.4489\n",
      "Epoch 54/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7907 - loss: 0.4469\n",
      "Epoch 55/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.7889 - loss: 0.4454\n",
      "Epoch 56/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.7855 - loss: 0.4464\n",
      "Epoch 57/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7939 - loss: 0.4410\n",
      "Epoch 58/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.7879 - loss: 0.4450\n",
      "Epoch 59/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7896 - loss: 0.4450\n",
      "Epoch 60/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.7894 - loss: 0.4449\n",
      "Epoch 61/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.7973 - loss: 0.4433\n",
      "Epoch 62/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7952 - loss: 0.4384\n",
      "Epoch 63/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.7878 - loss: 0.4503\n",
      "Epoch 64/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.7903 - loss: 0.4492\n",
      "Epoch 65/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.7892 - loss: 0.4460\n",
      "Epoch 66/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7878 - loss: 0.4474\n",
      "Epoch 67/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.7952 - loss: 0.4359\n",
      "Epoch 68/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.7857 - loss: 0.4477\n",
      "Epoch 69/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.7915 - loss: 0.4442\n",
      "Epoch 70/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.7931 - loss: 0.4402\n",
      "Epoch 71/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7923 - loss: 0.4412\n",
      "Epoch 72/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.7834 - loss: 0.4466\n",
      "Epoch 73/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.7974 - loss: 0.4359\n",
      "Epoch 74/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.7956 - loss: 0.4352\n",
      "Epoch 75/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7935 - loss: 0.4401\n",
      "Epoch 76/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7937 - loss: 0.4361\n",
      "Epoch 77/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.7986 - loss: 0.4340\n",
      "Epoch 78/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.7918 - loss: 0.4371\n",
      "Epoch 79/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.7869 - loss: 0.4469\n",
      "Epoch 80/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.8012 - loss: 0.4295\n",
      "Epoch 81/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7854 - loss: 0.4477\n",
      "Epoch 82/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.7980 - loss: 0.4336\n",
      "Epoch 83/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.7961 - loss: 0.4367\n",
      "Epoch 84/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.7951 - loss: 0.4441\n",
      "Epoch 85/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.7905 - loss: 0.4405\n",
      "Epoch 86/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.7886 - loss: 0.4410\n",
      "Epoch 87/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.7868 - loss: 0.4502\n",
      "Epoch 88/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.8017 - loss: 0.4248\n",
      "Epoch 89/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.7932 - loss: 0.4421\n",
      "Epoch 90/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.7894 - loss: 0.4448\n",
      "Epoch 91/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.7868 - loss: 0.4461\n",
      "Epoch 92/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7884 - loss: 0.4422\n",
      "Epoch 93/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7923 - loss: 0.4378\n",
      "Epoch 94/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.7917 - loss: 0.4381\n",
      "Epoch 95/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7895 - loss: 0.4447\n",
      "Epoch 96/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.7975 - loss: 0.4331\n",
      "Epoch 97/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.7968 - loss: 0.4399\n",
      "Epoch 98/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.7898 - loss: 0.4444\n",
      "Epoch 99/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.7993 - loss: 0.4311\n",
      "Epoch 100/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7890 - loss: 0.4382\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.7803 - loss: 0.4424\n",
      "[0.4538438618183136, 0.7739999890327454]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85      1593\n",
      "           1       0.47      0.76      0.58       407\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.70      0.77      0.71      2000\n",
      "weighted avg       0.83      0.77      0.79      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_sm = ANN(X_sm, y_sm, X_test, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sm_updated = []\n",
    "for i in y_pred_sm:\n",
    "    if i > 0.35:\n",
    "        y_pred_sm_updated.append(1)\n",
    "    else:\n",
    "        y_pred_sm_updated.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85      1337\n",
      "           1       0.76      0.47      0.58       663\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.77      0.70      0.71      2000\n",
      "weighted avg       0.77      0.77      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_sm_updated, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here the SMOTE method worked the best for us, so we use the model using imbalanced dataset technique as SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush R\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5488 - loss: 0.6861\n",
      "Epoch 2/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6439 - loss: 0.6504\n",
      "Epoch 3/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6817 - loss: 0.6087\n",
      "Epoch 4/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 0.5562\n",
      "Epoch 5/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7310 - loss: 0.5399\n",
      "Epoch 6/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.5228\n",
      "Epoch 7/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7535 - loss: 0.5174\n",
      "Epoch 8/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.5072\n",
      "Epoch 9/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7590 - loss: 0.5039\n",
      "Epoch 10/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.4832\n",
      "Epoch 11/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.4849\n",
      "Epoch 12/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7652 - loss: 0.4835\n",
      "Epoch 13/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.4784\n",
      "Epoch 14/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.4781\n",
      "Epoch 15/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7667 - loss: 0.4768\n",
      "Epoch 16/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.4785\n",
      "Epoch 17/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.4717\n",
      "Epoch 18/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.4637\n",
      "Epoch 19/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 0.4632\n",
      "Epoch 20/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.4684\n",
      "Epoch 21/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.4631\n",
      "Epoch 22/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7797 - loss: 0.4621\n",
      "Epoch 23/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7770 - loss: 0.4627\n",
      "Epoch 24/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.4615\n",
      "Epoch 25/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7770 - loss: 0.4573\n",
      "Epoch 26/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7715 - loss: 0.4620\n",
      "Epoch 27/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7794 - loss: 0.4519\n",
      "Epoch 28/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.4585\n",
      "Epoch 29/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4601\n",
      "Epoch 30/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.4543\n",
      "Epoch 31/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.4564\n",
      "Epoch 32/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.4624\n",
      "Epoch 33/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7821 - loss: 0.4580\n",
      "Epoch 34/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7793 - loss: 0.4518\n",
      "Epoch 35/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7762 - loss: 0.4554\n",
      "Epoch 36/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.4527\n",
      "Epoch 37/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7799 - loss: 0.4477\n",
      "Epoch 38/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.4485\n",
      "Epoch 39/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4565\n",
      "Epoch 40/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.4497\n",
      "Epoch 41/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.4577\n",
      "Epoch 42/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7756 - loss: 0.4512\n",
      "Epoch 43/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7762 - loss: 0.4572\n",
      "Epoch 44/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7800 - loss: 0.4500\n",
      "Epoch 45/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7820 - loss: 0.4455\n",
      "Epoch 46/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.4427\n",
      "Epoch 47/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.4503\n",
      "Epoch 48/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.4484\n",
      "Epoch 49/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.4467\n",
      "Epoch 50/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.4391\n",
      "Epoch 51/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7820 - loss: 0.4447\n",
      "Epoch 52/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.4440\n",
      "Epoch 53/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7860 - loss: 0.4437\n",
      "Epoch 54/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 0.4539\n",
      "Epoch 55/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7794 - loss: 0.4487\n",
      "Epoch 56/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.4430\n",
      "Epoch 57/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.4525\n",
      "Epoch 58/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7909 - loss: 0.4367\n",
      "Epoch 59/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4481\n",
      "Epoch 60/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.4445\n",
      "Epoch 61/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.4530\n",
      "Epoch 62/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.4377\n",
      "Epoch 63/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.4509\n",
      "Epoch 64/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7796 - loss: 0.4470\n",
      "Epoch 65/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.4413\n",
      "Epoch 66/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.4540\n",
      "Epoch 67/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.4479\n",
      "Epoch 68/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.4521\n",
      "Epoch 69/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.4406\n",
      "Epoch 70/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.4395\n",
      "Epoch 71/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.4426\n",
      "Epoch 72/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.4351\n",
      "Epoch 73/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.4446\n",
      "Epoch 74/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7797 - loss: 0.4487\n",
      "Epoch 75/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.4420\n",
      "Epoch 76/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.4522\n",
      "Epoch 77/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.4394\n",
      "Epoch 78/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.4393\n",
      "Epoch 79/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7864 - loss: 0.4438\n",
      "Epoch 80/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.4421\n",
      "Epoch 81/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.4415\n",
      "Epoch 82/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.4425\n",
      "Epoch 83/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.4434\n",
      "Epoch 84/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.4406\n",
      "Epoch 85/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.4380\n",
      "Epoch 86/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.4466\n",
      "Epoch 87/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.4447\n",
      "Epoch 88/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.4410\n",
      "Epoch 89/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4369\n",
      "Epoch 90/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7851 - loss: 0.4387\n",
      "Epoch 91/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.4453\n",
      "Epoch 92/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.4485\n",
      "Epoch 93/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 0.4472\n",
      "Epoch 94/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.4464\n",
      "Epoch 95/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7875 - loss: 0.4371\n",
      "Epoch 96/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.4478\n",
      "Epoch 97/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.4445\n",
      "Epoch 98/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7860 - loss: 0.4414\n",
      "Epoch 99/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.4434\n",
      "Epoch 100/100\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.4431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c6df8575c0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(12, input_shape=(12, ), activation='relu'),\n",
    "    keras.layers.Dense(6, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_sm, y_sm, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7737 - loss: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49060243368148804, 0.7595000267028809]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.94      0.83      1258\n",
      "         1.0       0.82      0.45      0.58       742\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.78      0.70      0.71      2000\n",
      "weighted avg       0.77      0.76      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
